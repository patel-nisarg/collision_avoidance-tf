{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collision Avoidance - Live View\n",
    "\n",
    "This notebook will be used to move the bot using the trained collision model.\n",
    "\n",
    "## Load the trained model\n",
    "\n",
    "An h5 file can be used or a folder path can be provided that contains the saved TensorFlow model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "model = keras.models.load_model('tf_collision_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load required modules\n",
    "\n",
    "Modules required are for camera, as well converting raw frames into input Tensors for the model. The input shape should be (224, 224, 3). I.e. 3 colour channels. Traitlet widgets allows visualization of camera. Jetbot module controls the Adafruit motor drivers via PWM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "import traitlets\n",
    "from IPython.display import display\n",
    "import ipywidgets.widgets as widgets\n",
    "from jetbot import Camera, bgr8_to_jpeg, Robot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate Widgets and Robot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera = Camera.instance(width=224, height=224)\n",
    "image = widgets.Image(format='jpeg', width=224, height=224)\n",
    "blocked_slider = widgets.FloatSlider(description='blocked', min=0.0, max=1.0, orientation='vertical')\n",
    "speed_slider = widgets.FloatSlider(description='speed', min=0.0, max=0.5, value=0.0, step=0.01, orientation='horizontal')\n",
    "\n",
    "camera_link = traitlets.dlink((camera, 'value'), (image, 'value'), transform=bgr8_to_jpeg)\n",
    "\n",
    "robot = Robot()\n",
    "\n",
    "display(widgets.VBox([widgets.HBox([image, blocked_slider]), speed_slider]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll create a function that will get called whenever the camera's value changes.  This function will do the following steps\n",
    "\n",
    "1. Pre-process the camera image\n",
    "2. Execute the neural network\n",
    "3. While the neural network output indicates we're blocked, we'll turn left, otherwise we go forward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "image_size = 224\n",
    "\n",
    "def update(change):\n",
    "    global blocked_slider, robot\n",
    "    x = change['new'] \n",
    "    img = load_img(img_path, color_mode='rgb', target_size=(image_size, image_size))\n",
    "    img_arr = img_to_array(img=img)\n",
    "    img_arr = np.array([img_arr]) * 1.0 / 255\n",
    "    predict = model.predict(img_arr)\n",
    "    \n",
    "    blocked_slider.value = 1-predict\n",
    "    \n",
    "    if predict < 0.75:\n",
    "        robot.forward(speed_slider.value)\n",
    "    else:\n",
    "        robot.left(speed_slider.value)\n",
    "    \n",
    "    time.sleep(0.001)\n",
    "        \n",
    "update({'new': camera.value}) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attach the update function to the value of the camera. This feeds the live image to the update function whereby the robot makes a decision as to whether to move forward in a free path or turn to avoid an obstacle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera.observe(update, names='value')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Emergency Stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "camera.unobserve(update, names='value')\n",
    "\n",
    "time.sleep(0.1)  # add a small sleep to make sure frames have finished processing\n",
    "\n",
    "robot.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run without streaming video to the browser. Camera will unlink."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_link.unlink()  # don't stream to browser (will still run camera)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Continue streaming..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_link.link()  # stream to browser (wont run camera)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Close the camera conneciton when complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
